{
  "best_global_step": 628,
  "best_metric": 0.971241309607669,
  "best_model_checkpoint": "./results\\checkpoint-628",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 942,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06369426751592357,
      "grad_norm": 2146.909423828125,
      "learning_rate": 1.44e-06,
      "loss": 0.7021,
      "step": 10
    },
    {
      "epoch": 0.12738853503184713,
      "grad_norm": 465.4390869140625,
      "learning_rate": 3.04e-06,
      "loss": 0.6985,
      "step": 20
    },
    {
      "epoch": 0.1910828025477707,
      "grad_norm": 151.57655334472656,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.7033,
      "step": 30
    },
    {
      "epoch": 0.25477707006369427,
      "grad_norm": 105.9228286743164,
      "learning_rate": 6.24e-06,
      "loss": 0.698,
      "step": 40
    },
    {
      "epoch": 0.3184713375796178,
      "grad_norm": 79.9930648803711,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.7004,
      "step": 50
    },
    {
      "epoch": 0.3821656050955414,
      "grad_norm": 89.48615264892578,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.6959,
      "step": 60
    },
    {
      "epoch": 0.445859872611465,
      "grad_norm": 36.739959716796875,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.6974,
      "step": 70
    },
    {
      "epoch": 0.5095541401273885,
      "grad_norm": 129.00653076171875,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.6946,
      "step": 80
    },
    {
      "epoch": 0.5732484076433121,
      "grad_norm": 32.39575958251953,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.6953,
      "step": 90
    },
    {
      "epoch": 0.6369426751592356,
      "grad_norm": 79.7783203125,
      "learning_rate": 1.584e-05,
      "loss": 0.7002,
      "step": 100
    },
    {
      "epoch": 0.7006369426751592,
      "grad_norm": 47.245487213134766,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.6997,
      "step": 110
    },
    {
      "epoch": 0.7643312101910829,
      "grad_norm": 15.23522663116455,
      "learning_rate": 1.904e-05,
      "loss": 0.6974,
      "step": 120
    },
    {
      "epoch": 0.8280254777070064,
      "grad_norm": 6.800637245178223,
      "learning_rate": 1.9902080783353734e-05,
      "loss": 0.6997,
      "step": 130
    },
    {
      "epoch": 0.89171974522293,
      "grad_norm": 9.438278198242188,
      "learning_rate": 1.9657282741738068e-05,
      "loss": 0.7105,
      "step": 140
    },
    {
      "epoch": 0.9554140127388535,
      "grad_norm": 9.150992393493652,
      "learning_rate": 1.94124847001224e-05,
      "loss": 0.6913,
      "step": 150
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4984025559105431,
      "eval_f1": 0.3326226012793177,
      "eval_f1_drug": 0.6652452025586354,
      "eval_loss": 0.6934217810630798,
      "eval_precision": 0.24920127795527156,
      "eval_precision_drug": 0.4984025559105431,
      "eval_recall": 0.5,
      "eval_recall_drug": 1.0,
      "eval_runtime": 124.5312,
      "eval_samples_per_second": 2.513,
      "eval_steps_per_second": 0.161,
      "step": 157
    },
    {
      "epoch": 1.019108280254777,
      "grad_norm": 9.528899192810059,
      "learning_rate": 1.9167686658506735e-05,
      "loss": 0.7029,
      "step": 160
    },
    {
      "epoch": 1.0828025477707006,
      "grad_norm": 7.57336950302124,
      "learning_rate": 1.8922888616891065e-05,
      "loss": 0.6735,
      "step": 170
    },
    {
      "epoch": 1.1464968152866242,
      "grad_norm": 8.980854988098145,
      "learning_rate": 1.86780905752754e-05,
      "loss": 0.7154,
      "step": 180
    },
    {
      "epoch": 1.2101910828025477,
      "grad_norm": 3.5234968662261963,
      "learning_rate": 1.8433292533659732e-05,
      "loss": 0.7204,
      "step": 190
    },
    {
      "epoch": 1.2738853503184713,
      "grad_norm": 4.5980987548828125,
      "learning_rate": 1.8188494492044066e-05,
      "loss": 0.699,
      "step": 200
    },
    {
      "epoch": 1.3375796178343948,
      "grad_norm": 9.980793952941895,
      "learning_rate": 1.79436964504284e-05,
      "loss": 0.693,
      "step": 210
    },
    {
      "epoch": 1.4012738853503186,
      "grad_norm": 10.850472450256348,
      "learning_rate": 1.769889840881273e-05,
      "loss": 0.695,
      "step": 220
    },
    {
      "epoch": 1.4649681528662422,
      "grad_norm": 9.654735565185547,
      "learning_rate": 1.7454100367197063e-05,
      "loss": 0.7078,
      "step": 230
    },
    {
      "epoch": 1.5286624203821657,
      "grad_norm": 2.7130277156829834,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 0.6987,
      "step": 240
    },
    {
      "epoch": 1.5923566878980893,
      "grad_norm": 5.233656406402588,
      "learning_rate": 1.696450428396573e-05,
      "loss": 0.6893,
      "step": 250
    },
    {
      "epoch": 1.6560509554140128,
      "grad_norm": 2.8927059173583984,
      "learning_rate": 1.6719706242350063e-05,
      "loss": 0.6934,
      "step": 260
    },
    {
      "epoch": 1.7197452229299364,
      "grad_norm": 2.4575836658477783,
      "learning_rate": 1.6474908200734397e-05,
      "loss": 0.6874,
      "step": 270
    },
    {
      "epoch": 1.78343949044586,
      "grad_norm": 3.0384371280670166,
      "learning_rate": 1.6230110159118727e-05,
      "loss": 0.7138,
      "step": 280
    },
    {
      "epoch": 1.8471337579617835,
      "grad_norm": 1.961472511291504,
      "learning_rate": 1.5985312117503064e-05,
      "loss": 0.6762,
      "step": 290
    },
    {
      "epoch": 1.910828025477707,
      "grad_norm": 1.9696595668792725,
      "learning_rate": 1.5740514075887394e-05,
      "loss": 0.7075,
      "step": 300
    },
    {
      "epoch": 1.9745222929936306,
      "grad_norm": 2.1046459674835205,
      "learning_rate": 1.5495716034271727e-05,
      "loss": 0.691,
      "step": 310
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4984025559105431,
      "eval_f1": 0.3326226012793177,
      "eval_f1_drug": 0.6652452025586354,
      "eval_loss": 0.6929996013641357,
      "eval_precision": 0.24920127795527156,
      "eval_precision_drug": 0.4984025559105431,
      "eval_recall": 0.5,
      "eval_recall_drug": 1.0,
      "eval_runtime": 30.1878,
      "eval_samples_per_second": 10.368,
      "eval_steps_per_second": 0.663,
      "step": 314
    },
    {
      "epoch": 2.038216560509554,
      "grad_norm": 1.6281605958938599,
      "learning_rate": 1.5250917992656061e-05,
      "loss": 0.691,
      "step": 320
    },
    {
      "epoch": 2.1019108280254777,
      "grad_norm": 2.4230973720550537,
      "learning_rate": 1.5006119951040393e-05,
      "loss": 0.696,
      "step": 330
    },
    {
      "epoch": 2.1656050955414012,
      "grad_norm": 4.143771171569824,
      "learning_rate": 1.4761321909424726e-05,
      "loss": 0.7014,
      "step": 340
    },
    {
      "epoch": 2.229299363057325,
      "grad_norm": 14.074790954589844,
      "learning_rate": 1.4516523867809058e-05,
      "loss": 0.7139,
      "step": 350
    },
    {
      "epoch": 2.2929936305732483,
      "grad_norm": 19.606042861938477,
      "learning_rate": 1.4271725826193392e-05,
      "loss": 0.6708,
      "step": 360
    },
    {
      "epoch": 2.356687898089172,
      "grad_norm": 50.85918426513672,
      "learning_rate": 1.4026927784577723e-05,
      "loss": 0.6187,
      "step": 370
    },
    {
      "epoch": 2.4203821656050954,
      "grad_norm": 36.308231353759766,
      "learning_rate": 1.3782129742962059e-05,
      "loss": 0.523,
      "step": 380
    },
    {
      "epoch": 2.484076433121019,
      "grad_norm": 14.582531929016113,
      "learning_rate": 1.353733170134639e-05,
      "loss": 0.3519,
      "step": 390
    },
    {
      "epoch": 2.5477707006369426,
      "grad_norm": 17.72960090637207,
      "learning_rate": 1.3292533659730724e-05,
      "loss": 0.2074,
      "step": 400
    },
    {
      "epoch": 2.611464968152866,
      "grad_norm": 139.86679077148438,
      "learning_rate": 1.3047735618115056e-05,
      "loss": 0.1051,
      "step": 410
    },
    {
      "epoch": 2.6751592356687897,
      "grad_norm": 1.6579235792160034,
      "learning_rate": 1.2802937576499388e-05,
      "loss": 0.0954,
      "step": 420
    },
    {
      "epoch": 2.738853503184713,
      "grad_norm": 0.6884428858757019,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 0.04,
      "step": 430
    },
    {
      "epoch": 2.802547770700637,
      "grad_norm": 0.8594653010368347,
      "learning_rate": 1.2313341493268055e-05,
      "loss": 0.1401,
      "step": 440
    },
    {
      "epoch": 2.8662420382165603,
      "grad_norm": 0.7466310858726501,
      "learning_rate": 1.2068543451652388e-05,
      "loss": 0.2769,
      "step": 450
    },
    {
      "epoch": 2.9299363057324843,
      "grad_norm": 1.1663239002227783,
      "learning_rate": 1.182374541003672e-05,
      "loss": 0.1568,
      "step": 460
    },
    {
      "epoch": 2.9936305732484074,
      "grad_norm": 0.5751352906227112,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 0.0036,
      "step": 470
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9616613418530351,
      "eval_f1": 0.9616609505144538,
      "eval_f1_drug": 0.9617834394904459,
      "eval_loss": 0.20167359709739685,
      "eval_precision": 0.9617190690077583,
      "eval_precision_drug": 0.9556962025316456,
      "eval_recall": 0.9616813653437857,
      "eval_recall_drug": 0.967948717948718,
      "eval_runtime": 28.9651,
      "eval_samples_per_second": 10.806,
      "eval_steps_per_second": 0.69,
      "step": 471
    },
    {
      "epoch": 3.0573248407643314,
      "grad_norm": 0.17002713680267334,
      "learning_rate": 1.1334149326805385e-05,
      "loss": 0.0025,
      "step": 480
    },
    {
      "epoch": 3.121019108280255,
      "grad_norm": 0.22299960255622864,
      "learning_rate": 1.108935128518972e-05,
      "loss": 0.1514,
      "step": 490
    },
    {
      "epoch": 3.1847133757961785,
      "grad_norm": 0.07438234984874725,
      "learning_rate": 1.0844553243574052e-05,
      "loss": 0.0702,
      "step": 500
    },
    {
      "epoch": 3.248407643312102,
      "grad_norm": 8.954296112060547,
      "learning_rate": 1.0599755201958386e-05,
      "loss": 0.1672,
      "step": 510
    },
    {
      "epoch": 3.3121019108280256,
      "grad_norm": 0.16919681429862976,
      "learning_rate": 1.0354957160342718e-05,
      "loss": 0.0843,
      "step": 520
    },
    {
      "epoch": 3.375796178343949,
      "grad_norm": 0.15693771839141846,
      "learning_rate": 1.0110159118727053e-05,
      "loss": 0.0539,
      "step": 530
    },
    {
      "epoch": 3.4394904458598727,
      "grad_norm": 0.10633375495672226,
      "learning_rate": 9.865361077111385e-06,
      "loss": 0.0367,
      "step": 540
    },
    {
      "epoch": 3.5031847133757963,
      "grad_norm": 0.07749690860509872,
      "learning_rate": 9.620563035495716e-06,
      "loss": 0.0853,
      "step": 550
    },
    {
      "epoch": 3.56687898089172,
      "grad_norm": 2.9140567779541016,
      "learning_rate": 9.37576499388005e-06,
      "loss": 0.1498,
      "step": 560
    },
    {
      "epoch": 3.6305732484076434,
      "grad_norm": 0.0649719089269638,
      "learning_rate": 9.130966952264383e-06,
      "loss": 0.0011,
      "step": 570
    },
    {
      "epoch": 3.694267515923567,
      "grad_norm": 0.039542753249406815,
      "learning_rate": 8.886168910648715e-06,
      "loss": 0.1559,
      "step": 580
    },
    {
      "epoch": 3.7579617834394905,
      "grad_norm": 136.37384033203125,
      "learning_rate": 8.641370869033049e-06,
      "loss": 0.0874,
      "step": 590
    },
    {
      "epoch": 3.821656050955414,
      "grad_norm": 0.10645672678947449,
      "learning_rate": 8.396572827417382e-06,
      "loss": 0.0938,
      "step": 600
    },
    {
      "epoch": 3.8853503184713376,
      "grad_norm": 0.04667143523693085,
      "learning_rate": 8.151774785801714e-06,
      "loss": 0.001,
      "step": 610
    },
    {
      "epoch": 3.949044585987261,
      "grad_norm": 0.027900781482458115,
      "learning_rate": 7.906976744186048e-06,
      "loss": 0.0008,
      "step": 620
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9712460063897763,
      "eval_f1": 0.971241309607669,
      "eval_f1_drug": 0.9716088328075709,
      "eval_loss": 0.2084774225950241,
      "eval_precision": 0.9716819221967963,
      "eval_precision_drug": 0.9565217391304348,
      "eval_recall": 0.9712967499591704,
      "eval_recall_drug": 0.9871794871794872,
      "eval_runtime": 29.5951,
      "eval_samples_per_second": 10.576,
      "eval_steps_per_second": 0.676,
      "step": 628
    },
    {
      "epoch": 4.012738853503185,
      "grad_norm": 0.03558732941746712,
      "learning_rate": 7.66217870257038e-06,
      "loss": 0.0007,
      "step": 630
    },
    {
      "epoch": 4.076433121019108,
      "grad_norm": 0.03080790676176548,
      "learning_rate": 7.417380660954713e-06,
      "loss": 0.1507,
      "step": 640
    },
    {
      "epoch": 4.140127388535032,
      "grad_norm": 0.180972158908844,
      "learning_rate": 7.172582619339046e-06,
      "loss": 0.0913,
      "step": 650
    },
    {
      "epoch": 4.203821656050955,
      "grad_norm": 0.06701374799013138,
      "learning_rate": 6.927784577723379e-06,
      "loss": 0.0007,
      "step": 660
    },
    {
      "epoch": 4.267515923566879,
      "grad_norm": 0.032282643020153046,
      "learning_rate": 6.682986536107712e-06,
      "loss": 0.0006,
      "step": 670
    },
    {
      "epoch": 4.3312101910828025,
      "grad_norm": 0.0676448792219162,
      "learning_rate": 6.438188494492044e-06,
      "loss": 0.0007,
      "step": 680
    },
    {
      "epoch": 4.3949044585987265,
      "grad_norm": 0.034352004528045654,
      "learning_rate": 6.193390452876378e-06,
      "loss": 0.0006,
      "step": 690
    },
    {
      "epoch": 4.45859872611465,
      "grad_norm": 0.03948550298810005,
      "learning_rate": 5.948592411260711e-06,
      "loss": 0.0006,
      "step": 700
    },
    {
      "epoch": 4.522292993630574,
      "grad_norm": 0.01965772733092308,
      "learning_rate": 5.703794369645044e-06,
      "loss": 0.0006,
      "step": 710
    },
    {
      "epoch": 4.585987261146497,
      "grad_norm": 0.07662328332662582,
      "learning_rate": 5.458996328029377e-06,
      "loss": 0.0006,
      "step": 720
    },
    {
      "epoch": 4.649681528662421,
      "grad_norm": 0.027898475527763367,
      "learning_rate": 5.214198286413709e-06,
      "loss": 0.0816,
      "step": 730
    },
    {
      "epoch": 4.713375796178344,
      "grad_norm": 0.029349006712436676,
      "learning_rate": 4.969400244798042e-06,
      "loss": 0.0005,
      "step": 740
    },
    {
      "epoch": 4.777070063694268,
      "grad_norm": 0.028246784582734108,
      "learning_rate": 4.724602203182375e-06,
      "loss": 0.0966,
      "step": 750
    },
    {
      "epoch": 4.840764331210191,
      "grad_norm": 0.03400307521224022,
      "learning_rate": 4.4798041615667074e-06,
      "loss": 0.167,
      "step": 760
    },
    {
      "epoch": 4.904458598726115,
      "grad_norm": 0.06481624394655228,
      "learning_rate": 4.235006119951041e-06,
      "loss": 0.0916,
      "step": 770
    },
    {
      "epoch": 4.968152866242038,
      "grad_norm": 158.8124542236328,
      "learning_rate": 3.990208078335374e-06,
      "loss": 0.0927,
      "step": 780
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9680511182108626,
      "eval_f1": 0.9680481829318089,
      "eval_f1_drug": 0.9683544303797469,
      "eval_loss": 0.21635305881500244,
      "eval_precision": 0.9683210784313725,
      "eval_precision_drug": 0.95625,
      "eval_recall": 0.9680916217540421,
      "eval_recall_drug": 0.9807692307692307,
      "eval_runtime": 36.417,
      "eval_samples_per_second": 8.595,
      "eval_steps_per_second": 0.549,
      "step": 785
    },
    {
      "epoch": 5.031847133757962,
      "grad_norm": 0.06139751151204109,
      "learning_rate": 3.7454100367197067e-06,
      "loss": 0.0388,
      "step": 790
    },
    {
      "epoch": 5.095541401273885,
      "grad_norm": 0.033089056611061096,
      "learning_rate": 3.5006119951040398e-06,
      "loss": 0.0005,
      "step": 800
    },
    {
      "epoch": 5.159235668789809,
      "grad_norm": 0.03670847415924072,
      "learning_rate": 3.2558139534883724e-06,
      "loss": 0.0005,
      "step": 810
    },
    {
      "epoch": 5.222929936305732,
      "grad_norm": 0.043541133403778076,
      "learning_rate": 3.011015911872705e-06,
      "loss": 0.0004,
      "step": 820
    },
    {
      "epoch": 5.286624203821656,
      "grad_norm": 0.9705921411514282,
      "learning_rate": 2.766217870257038e-06,
      "loss": 0.0005,
      "step": 830
    },
    {
      "epoch": 5.350318471337579,
      "grad_norm": 0.10735864192247391,
      "learning_rate": 2.521419828641371e-06,
      "loss": 0.0004,
      "step": 840
    },
    {
      "epoch": 5.414012738853503,
      "grad_norm": 0.018398432061076164,
      "learning_rate": 2.276621787025704e-06,
      "loss": 0.0004,
      "step": 850
    },
    {
      "epoch": 5.477707006369426,
      "grad_norm": 0.014368891716003418,
      "learning_rate": 2.031823745410037e-06,
      "loss": 0.0004,
      "step": 860
    },
    {
      "epoch": 5.54140127388535,
      "grad_norm": 59.361549377441406,
      "learning_rate": 1.7870257037943697e-06,
      "loss": 0.2519,
      "step": 870
    },
    {
      "epoch": 5.6050955414012735,
      "grad_norm": 0.043514180928468704,
      "learning_rate": 1.5422276621787028e-06,
      "loss": 0.0981,
      "step": 880
    },
    {
      "epoch": 5.6687898089171975,
      "grad_norm": 0.024256384000182152,
      "learning_rate": 1.2974296205630357e-06,
      "loss": 0.0004,
      "step": 890
    },
    {
      "epoch": 5.732484076433121,
      "grad_norm": 0.03583161532878876,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.0005,
      "step": 900
    },
    {
      "epoch": 5.796178343949045,
      "grad_norm": 0.036288462579250336,
      "learning_rate": 8.078335373317014e-07,
      "loss": 0.0004,
      "step": 910
    },
    {
      "epoch": 5.859872611464969,
      "grad_norm": 0.027787841856479645,
      "learning_rate": 5.630354957160343e-07,
      "loss": 0.0004,
      "step": 920
    },
    {
      "epoch": 5.923566878980892,
      "grad_norm": 0.02065620757639408,
      "learning_rate": 3.182374541003672e-07,
      "loss": 0.0004,
      "step": 930
    },
    {
      "epoch": 5.987261146496815,
      "grad_norm": 0.034244660288095474,
      "learning_rate": 7.343941248470012e-08,
      "loss": 0.0015,
      "step": 940
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9680511182108626,
      "eval_f1": 0.968050792095378,
      "eval_f1_drug": 0.9681528662420382,
      "eval_loss": 0.22423633933067322,
      "eval_precision": 0.9681094324213966,
      "eval_precision_drug": 0.9620253164556962,
      "eval_recall": 0.9680712069247102,
      "eval_recall_drug": 0.9743589743589743,
      "eval_runtime": 29.472,
      "eval_samples_per_second": 10.62,
      "eval_steps_per_second": 0.679,
      "step": 942
    }
  ],
  "logging_steps": 10,
  "max_steps": 942,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 34927927380000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
